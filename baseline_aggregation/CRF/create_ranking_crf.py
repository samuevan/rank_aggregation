#use the final scores of the CRF to construct an output ranking
#this output ranking could be used to calc the metrics (MAP, NDCG...)

import os
import sys
import glob
import ipdb
import argparse

def write_user_ranking(user,items,size_ranking):
    
    s = str(user)+"\t["
    for i in range(size_ranking-1):        
        item,score = items[i]
        s += "%d:%.4f," %(item,score)

    item,score = items[-1]
    s += "%d:%.4f]\n" %(item,score)

    return s
    



'''
test_file : arquivo de teste usado pelo CRF. Este eh o arquivo de teste que foi convertido para o formato esperado pelo CRF
scores_file : arquivo contendo os scores que o CRF atribuiu para cada instancia
out_dir : pasta onde devem ser salvos os rankings gerados a partir dos scores
size_ranking : Tamanho do ranking de saida
partition : particao atual


Salva um arquivo contendo um ranking gerado a partir dos scores atribuidos pelo CRF
'''
def run(test_file_path, scores_file_path, out_dir, size_ranking, partition,run=0):


    test_file = open(test_file_path,'r')
    scores_file = open(scores_file_path,'r')



    name_f = partition +"run"+str(run)+".CRF.out"
    output_f = open(out_dir+name_f,"w")

    qid_past = -1

    crf_ranking = []
    #users = []
    for line_test,line_score in zip(test_file,scores_file):
        
        #nesse momento, as unicas informacoes importantes vindas do tokens_test
        #sao o id do usuario(qid) e o id do item (docid)        
        tokens_test = line_test.strip().split(" ")
        qid = int(tokens_test[1].split(":")[1])
        item = int(tokens_test[tokens_test.index("#docid") + 2])
        score = float(line_score)

        #salva o ranking para o usuario. Ordena os scores e pega os size_ranking 
        #maiores
        if qid_past != qid and qid_past != -1:
            crf_ranking.sort(key = lambda tup : tup[1],reverse=True)
            output_f.write(write_user_ranking(qid_past,crf_ranking,size_ranking))
            crf_ranking = [(item,score)]
            #users.append(qid_past)
        else:
            crf_ranking.append((item,score))

        qid_past = qid


    #dados do ultimo usuario
    crf_ranking.sort(key = lambda tup : tup[1],reverse=True)
    output_f.write(write_user_ranking(qid_past,crf_ranking,size_ranking))

    output_f.close()



def arg_parse():
    
    p = argparse.ArgumentParser()

    p.add_argument("--basedir",type=str,
        help="The dir where the scores and test files are stored." + \
            "When set the test and score files will be authomatically" + \
            "retrieved from this directory")
    p.add_argument("--test",type=str,help="The path for the test map to be used")
    p.add_argument("--scores_f", type=str,
        help="Path for the scores generated by the CRF (or any other)" + \
             "to the corresponding test file)")
    p.add_argument("-o","--out_dir", type=str,
        help="The path to store the output files")
    p.add_argument("--i2sug",type=int,default=10,
        help="The size of the output rankings")
    p.add_argument("-p","--part",type=str,
        help="The partition to be used")
    p.add_argument("--pini",type=int, default = 1,
        help="The first partition to be used whe the files are "+ \
        "automatically retrireved")
    p.add_argument("--pend",type=int,default = 5,
        help="The last partition to be used whe the files are "+ \
        "automatically retrireved")
    p.add_argument("-r","--run", type=int,
        help="The current run")


    parsed =  p.parse_args()

    if not parsed.out_dir:
        parsed.out_dir = os.path.join(parsed.basedir,"CRF_rankings/")

    return parsed

    

if __name__ == "__main__":
       
    args = arg_parse()

    if not os.path.isdir(args.out_dir):
        os.mkdir(args.out_dir)
    

    #when the parameter basedir is set we construct the rankings for all the 
    #score files in the Fold[#part] folders
    if args.basedir:
        for p in range(args.pini,args.pend+1):                       
            #get the test file
            args.test = os.path.join(args.basedir,"Fold"+str(p), 'test.map')
            #list all the score files in the folder
            score_files = sorted(glob.glob(os.path.join(args.basedir,"Fold"+str(p),
                        "*.scores")))

            partition = "u"+str(p)
            #construct the rankings for each score file
            for curr_run,score_file in enumerate(score_files):
                run(args.test,score_file,args.out_dir, args.i2sug,
                                    partition,run=curr_run)
    else:
        run(args.test,args.scores_f,args.out_dir,args.i2sug,args.part)

    
